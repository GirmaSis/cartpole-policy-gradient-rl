# Advanced Policy Gradient RL for CartPole

Implementations of **Actor-Critic** and **REINFORCE with Baseline** reinforcement learning algorithms to solve the **CartPole-v1** environment using **PyTorch**. It demonstrates advanced **policy optimization techniques** and provides **visual analysis** of training performance.

## 🚀 Project Objectives
- Implement and compare **Actor-Critic** and **REINFORCE with Baseline** for **policy gradient reinforcement learning**.
- Train an agent to **balance a pole** on a moving cart efficiently.
- Optimize **policy learning stability** through **advantage estimation and baseline functions**.
- **Analyze performance** using training reward curves and **visualize training progress with GIFs**.

<p align="center">
  <img src="https://raw.githubusercontent.com/GirmaSis/cartpole-policy-gradient-rl/main/Figure_1.png" width="45%" />
  <img src="https://raw.githubusercontent.com/GirmaSis/cartpole-policy-gradient-rl/main/Figure_2.png" width="45%" />
</p>
<p align="center">
  <img src="https://github.com/GirmaSis/cartpole-policy-gradient-rl/blob/main/gifs_actor_critic/cartpole_episode_80.gif" width="50%" />
  <img src="https://raw.githubusercontent.com/GirmaSis/cartpole-policy-gradient-rl/main/gifs_REINFORCE/cartpole_episode_90.gif" width="50%" />

</p>

## 🏆 Why This Project is Unique
- **📈 Two core RL algorithms in one** → Learn **Actor-Critic vs. REINFORCE with Baseline**.
- **⚡ Stability improvements** → Uses **advantage estimation** and a **learned baseline** to reduce variance.
- **🔍 Efficient policy optimization** → Applies **LeakyReLU, Dropout**, and **Adaptive Learning Strategies**.
- **📊 Performance Tracking** → Plots **reward curves** and saves **GIFs of training episodes**.

